{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Apply trained VCD-Net model  \n",
    "This notebook demonstrates applying a VCD-Net  model for a light field reconstruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the parameters\n",
    "We define all parameters in a [configuration script config.py](./config.py). Make the edit according to specific application and dataset before running this notebook.  \n",
    "\n",
    "Typical parameters include:\n",
    "- **PSF.n_slices** : number of z slices of targeted 3-D reconstruction\n",
    "- **PSF.Nnum**     : number of pixels behind each lenslet\n",
    "- **label**        : label of the pretrained model to be used for inference\n",
    "- **VALID.lf2d_path**     : folder where the 2D light field images to be reconstructed are stored\n",
    "- **VALID.saving_path**   : folder where the reconstruced results will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\core.py:43: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\pooling.py:59: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Parameters defined in config.py:\n",
      "PSF related: \n",
      "    n_slices                         61                            \n",
      "    Nnum                             15                            \n",
      "Prediction related: \n",
      "    ckpt_dir                         E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\checkpoint\\tubulin_10x06_N15_OSR3_Crop240\\\n",
      "    lf2d_path                        E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\data\\tubesMacbook_Nnum15OSR3_Crop240_LF\\\n",
      "    saving_path                      E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\data\\tubesMacbook_Nnum15OSR3_Crop240_WF_Results/\n"
     ]
    }
   ],
   "source": [
    "from eval import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "\n",
    "print(\"Parameters defined in config.py:\")\n",
    "print(\"PSF related: \")\n",
    "for par, val in config.PSF.items():\n",
    "    print('    {:<30}   {:<30}'.format(par,val))\n",
    "        \n",
    "print(\"Prediction related: \")\n",
    "for par, val in config.VALID.items():\n",
    "    print('    {:<30}   {:<30}'.format(par,val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [!] E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\data\\tubesMacbook_Nnum15OSR3_Crop240_WF_Results/ exists ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 5635 from E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\data\\tubesMacbook_Nnum15OSR3_Crop240_LF\\\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\eval.py:75: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\model\\unet.py:57: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\core.py:386: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  unet/lf_extra: (1, 16, 16, 225)\n",
      "[TL] Conv2dLayer unet/conv1: shape:(7, 7, 225, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\convolution.py:203: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] SubpixelConv2d  interp/subpixel0: scale: 2 n_out_channel: 32 act: identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\super_resolution.py:89: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Conv2dLayer unet/interp/conv0: shape:(3, 3, 32, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel1: scale: 2 n_out_channel: 16 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv1: shape:(3, 3, 16, 32) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel2: scale: 2 n_out_channel: 8 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv2: shape:(3, 3, 8, 16) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel3: scale: 2 n_out_channel: 4 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv3: shape:(3, 3, 4, 8) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] Conv2dLayer unet/interp/conv_final: shape:(3, 3, 8, 8) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/interp/bn_final: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] Conv2dLayer unet/encoder/conv0: shape:(3, 3, 8, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn_0: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] Conv2dLayer unet/encoder/conv1: shape:(3, 3, 64, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 0 : (1, 256, 256, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] BatchNormLayer unet/encoder/bn1: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer unet/encoder/add1: size:(1, 256, 256, 128) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool1: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/conv2: shape:(3, 3, 128, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn2: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer unet/encoder/add2: size:(1, 128, 128, 256) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool2: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/conv3: shape:(3, 3, 256, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn3: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 64)\n",
      "(1, 256, 256, 64) (1, 256, 256, 64)\n",
      "encoder 1 : (1, 128, 128, 128)\n",
      "(1, 128, 128, 128)\n",
      "(1, 128, 128, 128) (1, 128, 128, 128)\n",
      "encoder 2 : (1, 64, 64, 256)\n",
      "(1, 64, 64, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] ElementwiseLayer unet/encoder/add3: size:(1, 64, 64, 512) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool3: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/conv4: shape:(3, 3, 512, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn4: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 256) (1, 64, 64, 256)\n",
      "encoder 3 : (1, 32, 32, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] ElementwiseLayer unet/encoder/add4: size:(1, 32, 32, 512) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool4: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/conv5: shape:(3, 3, 512, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn5: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer unet/encoder/add5: size:(1, 16, 16, 512) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool5: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] UpSampling2dLayer upsamplimg: is_scale:False size:(16, 16) method:0 align_corners:False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 512)\n",
      "(1, 32, 32, 512) (1, 32, 32, 0)\n",
      "encoder 4 : (1, 16, 16, 512)\n",
      "(1, 16, 16, 512)\n",
      "(1, 16, 16, 512) (1, 16, 16, 0)\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\convolution.py:538: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] ConcatLayer unet/decoder/concat1: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv2: shape:(3, 3, 1024, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 4 : (1, 16, 16, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] BatchNormLayer unet/decoder/bn2: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg2: is_scale:False size:(32, 32) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat2: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv3: shape:(3, 3, 1024, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/decoder/bn3: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 3 : (1, 32, 32, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] UpSampling2dLayer upsamplimg3: is_scale:False size:(64, 64) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat3: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv4: shape:(3, 3, 768, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/decoder/bn4: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 2 : (1, 64, 64, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] UpSampling2dLayer upsamplimg4: is_scale:False size:(128, 128) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat4: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv5: shape:(3, 3, 384, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/decoder/bn5: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 1 : (1, 128, 128, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] UpSampling2dLayer upsamplimg5: is_scale:False size:(256, 256) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat5: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv6: shape:(3, 3, 192, 61) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 0 : (1, 256, 256, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] BatchNormLayer unet/decoder/bn6: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg6: is_scale:False size:(256, 256) method:0 align_corners:False\n",
      "[TL] UpSampling2dLayer resize_final: is_scale:False size:[240, 240] method:0 align_corners:False\n",
      "[TL] InputLayer  unet/lf_extra: (1, 16, 16, 225)\n",
      "[TL] Conv2dLayer unet/conv1: shape:(7, 7, 225, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable unet/conv1/W_conv2d already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8390374e2938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0muse_cpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Dropbox\\Python\\VCD-Net\\vcdnet\\eval.py\u001b[0m in \u001b[0;36minfer\u001b[1;34m(epoch, batch_size, use_cpu, save_pb)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUNet_A\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;34m'beta'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUNet_C\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_slices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unet'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalize_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\Python\\VCD-Net\\vcdnet\\model\\unet.py\u001b[0m in \u001b[0;36mUNet_C\u001b[1;34m(lf_extra, n_slices, output_size, is_train, reuse, name, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlf_extra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lf_extra'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchannels_interp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'interp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_interp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\Python\\VCD-Net\\vcdnet\\model\\util\\utils.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(layer, n_filter, filter_size, stride, act, W_init, b_init, padding, name)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'conv2d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_filter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m def conv3d(layer, \n",
      "\u001b[1;32mE:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\convolution.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(layer, n_filter, filter_size, strides, act, padding, W_init, b_init, W_init_args, b_init_args, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[0;32m   1394\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1396\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   1397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\convolution.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, prev_layer, act, shape, strides, padding, W_init, b_init, W_init_args, b_init_args, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'W_conv2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLayersConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mW_init_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mb_init\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b_conv2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLayersConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mb_init_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1243\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[1;32m~\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"tensorflow/python\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[1;32m--> 868\u001b[1;33m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable unet/conv1/W_conv2d already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\admin\\.conda\\envs\\vcdnet\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "ckpt = 0 #0 means latest\n",
    "batch_size = 1\n",
    "use_cpu = 1                                             \n",
    "infer(ckpt, batch_size=batch_size, use_cpu=use_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "\n",
    "test_file = 'vcd-001-000009.tif'\n",
    "recon = get_and_rearrange3d(test_file, config.VALID.saving_path, normalize)\n",
    "# recons=np.ndarray([recon.shape[0],recon.shape[1],recon.shape[2],3])\n",
    "\n",
    "f=ipv.quickvolshow(recon)\n",
    "ipv.show()\n",
    "\n",
    "# ##threshold\n",
    "# a,b,c=np.where(recon>=0.1)\n",
    "# a=np.asarray(a,dtype='float64')\n",
    "# b=np.asarray(b,dtype='float64')\n",
    "# c=np.asarray(c,dtype='float64')\n",
    "\n",
    "# ##scatter\n",
    "# # f=ipv.quickscatter(a,b,c)\n",
    "# ipv.show()\n",
    "\n",
    "# ##surface\n",
    "# from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "# points=np.concatenate((np.expand_dims(a,axis=1),np.expand_dims(b,axis=1),np.expand_dims(c,axis=1)),axis=1)\n",
    "# hull = ConvexHull(points)\n",
    "# f=ipv.plot_trisurf(a,b,c, triangles=hull.simplices, color='red') ##surface\n",
    "# ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##bokeh embeds ipv figures as html exceeds the char limit for squarespace \n",
    "import ipyvolume\n",
    "import ipyvolume as ipv\n",
    "import vaex\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import CustomJS, ColumnDataSource\n",
    "import ipyvolume.bokeh\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.embed import components\n",
    "import ipywidgets\n",
    "\n",
    "ds = vaex.example()\n",
    "N = 5\n",
    "\n",
    "ipv.figure()\n",
    "quiver = ipv.quiver(ds.data.x[:N],  ds.data.y[:N],  ds.data.z[:N],\n",
    "                    ds.data.vx[:N], ds.data.vy[:N], ds.data.vz[:N],\n",
    "                    size=1, size_selected=5, color_selected=\"grey\")\n",
    "ipv.xyzlim(-30, 30)\n",
    "ipv.show()\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "xin=ds.data.Lz[:N]\n",
    "yin=ds.data.E[:N]\n",
    "data_source = ColumnDataSource(data=dict(x=xin.astype('uint8'), y=yin.astype('uint8')))\n",
    "p = figure(title=\"E Lz space\", tools='lasso_select', width=500, height=500)\n",
    "r = p.circle('x', 'y', source=data_source, color=\"navy\", alpha=0.2)\n",
    "ipyvolume.bokeh.link_data_source_selection_to_widget(data_source, quiver, 'selected')\n",
    "show(p)\n",
    "\n",
    "out = ipywidgets.Output()\n",
    "with out:\n",
    "    show(p)\n",
    "ipywidgets.HBox([out, ipv.gcc()])\n",
    "\n",
    "script, div = components((p))\n",
    "template_options = dict(extra_script_head=script + CDN.render_js() + CDN.render_css(),\n",
    "                        body_pre=\"<h2>Do selections in 2d (bokeh)<h2>\" + div + \"<h2>And see the selection in ipyvolume<h2>\")\n",
    "figCode=ipyvolume.embed.embed_html(\"tmp/bokeh.html\",\n",
    "                           [ipv.gcc(), ipyvolume.bokeh.wmh], all_states=True,\n",
    "                           template_options=template_options)\n",
    "\n",
    "!open tmp/bokeh.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=ipv.scatter(np.random.randn(1,10),np.random.randn(1,10),np.random.randn(1,10))\n",
    "f.send_state('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import mpld3\n",
    "\n",
    "test_file = 'vcd-001-000000.tif'\n",
    "recon = get_and_rearrange3d(test_file, config.VALID.saving_path, normalize)\n",
    "print(recon.shape)\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[recon.shape[0],recon.shape[2]*1/0.34]) \n",
    "xy_view = plt.subplot(gs[0])\n",
    "xy_view.imshow(np.sum(recon, axis=-1, keepdims=False),cmap='hot')\n",
    "xy_view.set_title('VCD-XY')\n",
    "plt.axis('off')\n",
    "xz_view = plt.subplot(gs[1])\n",
    "xz_view.imshow(np.transpose(np.sum(recon, axis=0, keepdims=False)),cmap='hot',aspect=1/0.34)\n",
    "xz_view.set_title('VCD-XZ')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "##create html file\n",
    "html_str = mpld3.fig_to_html(fig)\n",
    "Html_file= open(\"index.html\",\"w\")\n",
    "Html_file.write(html_str)\n",
    "Html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vcdnet",
   "language": "python",
   "name": "vcdnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
