{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Apply trained VCD-Net model  \n",
    "This notebook demonstrates applying a VCD-Net  model for a light field reconstruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the parameters\n",
    "We define all parameters in a [configuration script config.py](./config.py). Make the edit according to specific application and dataset before running this notebook.  \n",
    "\n",
    "Typical parameters include:\n",
    "- **PSF.n_slices** : number of z slices of targeted 3-D reconstruction\n",
    "- **PSF.Nnum**     : number of pixels behind each lenslet\n",
    "- **label**        : label of the pretrained model to be used for inference\n",
    "- **VALID.lf2d_path**     : folder where the 2D light field images to be reconstructed are stored\n",
    "- **VALID.saving_path**   : folder where the reconstruced results will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\core.py:43: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\pooling.py:59: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Parameters defined in config.py:\n",
      "PSF related: \n",
      "    n_slices                         61                            \n",
      "    Nnum                             15                            \n",
      "Prediction related: \n",
      "    ckpt_dir                         E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\checkpoint\\tubulin_10x06_N15_OSR3_Crop240\\\n",
      "    lf2d_path                        E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\data\\tubesMacbook_Nnum15OSR3_Crop240_LF\\\n",
      "    saving_path                      E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\data\\tubesMacbook_Nnum15OSR3_Crop240_WF_Results/\n"
     ]
    }
   ],
   "source": [
    "from eval import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "\n",
    "print(\"Parameters defined in config.py:\")\n",
    "print(\"PSF related: \")\n",
    "for par, val in config.PSF.items():\n",
    "    print('    {:<30}   {:<30}'.format(par,val))\n",
    "        \n",
    "print(\"Prediction related: \")\n",
    "for par, val in config.VALID.items():\n",
    "    print('    {:<30}   {:<30}'.format(par,val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [!] E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\data\\tubesMacbook_Nnum15OSR3_Crop240_WF_Results/ exists ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 5635 from E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\data\\tubesMacbook_Nnum15OSR3_Crop240_LF\\\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\eval.py:75: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\eval.py:82: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\model\\unet.py:57: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\core.py:386: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  unet/lf_extra: (1, 16, 16, 225)\n",
      "[TL] Conv2dLayer unet/conv1: shape:(7, 7, 225, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\convolution.py:203: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] SubpixelConv2d  interp/subpixel0: scale: 2 n_out_channel: 32 act: identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\super_resolution.py:89: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Conv2dLayer unet/interp/conv0: shape:(3, 3, 32, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel1: scale: 2 n_out_channel: 16 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv1: shape:(3, 3, 16, 32) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel2: scale: 2 n_out_channel: 8 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv2: shape:(3, 3, 8, 16) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel3: scale: 2 n_out_channel: 4 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv3: shape:(3, 3, 4, 8) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] Conv2dLayer unet/interp/conv_final: shape:(3, 3, 8, 8) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/interp/bn_final: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] Conv2dLayer unet/encoder/conv0: shape:(3, 3, 8, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn_0: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] Conv2dLayer unet/encoder/conv1: shape:(3, 3, 64, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn1: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer unet/encoder/add1: size:(1, 256, 256, 128) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool1: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/conv2: shape:(3, 3, 128, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn2: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer unet/encoder/add2: size:(1, 128, 128, 256) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool2: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/conv3: shape:(3, 3, 256, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn3: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 0 : (1, 256, 256, 64)\n",
      "(1, 256, 256, 64)\n",
      "(1, 256, 256, 64) (1, 256, 256, 64)\n",
      "encoder 1 : (1, 128, 128, 128)\n",
      "(1, 128, 128, 128)\n",
      "(1, 128, 128, 128) (1, 128, 128, 128)\n",
      "encoder 2 : (1, 64, 64, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] ElementwiseLayer unet/encoder/add3: size:(1, 64, 64, 512) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool3: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/conv4: shape:(3, 3, 512, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn4: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer unet/encoder/add4: size:(1, 32, 32, 512) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool4: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/conv5: shape:(3, 3, 512, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/encoder/bn5: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] ElementwiseLayer unet/encoder/add5: size:(1, 16, 16, 512) fn:add\n",
      "[TL] PoolLayer   unet/encoder/maxplool5: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] UpSampling2dLayer upsamplimg: is_scale:False size:(16, 16) method:0 align_corners:False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 256)\n",
      "(1, 64, 64, 256) (1, 64, 64, 256)\n",
      "encoder 3 : (1, 32, 32, 512)\n",
      "(1, 32, 32, 512)\n",
      "(1, 32, 32, 512) (1, 32, 32, 0)\n",
      "encoder 4 : (1, 16, 16, 512)\n",
      "(1, 16, 16, 512)\n",
      "(1, 16, 16, 512) (1, 16, 16, 0)\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\convolution.py:538: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] ConcatLayer unet/decoder/concat1: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv2: shape:(3, 3, 1024, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/decoder/bn2: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 4 : (1, 16, 16, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] UpSampling2dLayer upsamplimg2: is_scale:False size:(32, 32) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat2: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv3: shape:(3, 3, 1024, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/decoder/bn3: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg3: is_scale:False size:(64, 64) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat3: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv4: shape:(3, 3, 768, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/decoder/bn4: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg4: is_scale:False size:(128, 128) method:0 align_corners:False"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 3 : (1, 32, 32, 512)\n",
      "decoder 2 : (1, 64, 64, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TL] ConcatLayer unet/decoder/concat4: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv5: shape:(3, 3, 384, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/decoder/bn5: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 1 : (1, 128, 128, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] UpSampling2dLayer upsamplimg5: is_scale:False size:(256, 256) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat5: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv6: shape:(3, 3, 192, 61) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer unet/decoder/bn6: decay:0.900000 epsilon:0.000010 act:identity is_train:True\n",
      "[TL] UpSampling2dLayer upsamplimg6: is_scale:False size:(256, 256) method:0 align_corners:False\n",
      "[TL] UpSampling2dLayer resize_final: is_scale:False size:[240, 240] method:0 align_corners:False\n",
      "[TL] InputLayer  unet/lf_extra: (1, 16, 16, 225)\n",
      "[TL] Conv2dLayer unet/conv1: shape:(7, 7, 225, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel0: scale: 2 n_out_channel: 32 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv0: shape:(3, 3, 32, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel1: scale: 2 n_out_channel: 16 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv1: shape:(3, 3, 16, 32) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel2: scale: 2 n_out_channel: 8 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv2: shape:(3, 3, 8, 16) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] SubpixelConv2d  interp/subpixel3: scale: 2 n_out_channel: 4 act: identity\n",
      "[TL] Conv2dLayer unet/interp/conv3: shape:(3, 3, 4, 8) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] Conv2dLayer unet/interp/conv_final: shape:(3, 3, 8, 8) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/interp/in_final: epsilon:0.000010 act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 0 : (1, 256, 256, 128)\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\normalization.py:212: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\normalization.py:214: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Conv2dLayer unet/encoder/conv0: shape:(3, 3, 8, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/in_0: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_0/conv2d_conv2d: shape:(1, 1, 64, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_0/conv2din: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_0/conv_block1_conv2d: shape:(3, 3, 64, 32) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_0/conv_block1in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_0/conv_block2_conv2d: shape:(3, 3, 32, 32) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_0/conv_block2in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_0/conv_block3_conv2d: shape:(3, 3, 32, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_0/conv_block3in: epsilon:0.000010 act:identity\n",
      "[TL] ConcatLayer unet/encoder/convblock_0/concat: axis: -1\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_0/in: epsilon:0.000010 act:identity\n",
      "[TL] ElementwiseLayer unet/encoder/convblock_0/merge_last: size:(1, 256, 256, 128) fn:add\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_0/nrom_last: epsilon:0.000010 act:identity\n",
      "[TL] PoolLayer   unet/encoder/maxplool1: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/convblock_1/conv2d_conv2d: shape:(1, 1, 128, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_1/conv2din: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_1/conv_block1_conv2d: shape:(3, 3, 128, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_1/conv_block1in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_1/conv_block2_conv2d: shape:(3, 3, 64, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_1/conv_block2in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_1/conv_block3_conv2d: shape:(3, 3, 64, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_1/conv_block3in: epsilon:0.000010 act:identity\n",
      "[TL] ConcatLayer unet/encoder/convblock_1/concat: axis: -1\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_1/in: epsilon:0.000010 act:identity\n",
      "[TL] ElementwiseLayer unet/encoder/convblock_1/merge_last: size:(1, 128, 128, 256) fn:add\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_1/nrom_last: epsilon:0.000010 act:identity\n",
      "[TL] PoolLayer   unet/encoder/maxplool2: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/convblock_2/conv2d_conv2d: shape:(1, 1, 256, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_2/conv2din: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_2/conv_block1_conv2d: shape:(3, 3, 256, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_2/conv_block1in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_2/conv_block2_conv2d: shape:(3, 3, 128, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_2/conv_block2in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_2/conv_block3_conv2d: shape:(3, 3, 128, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_2/conv_block3in: epsilon:0.000010 act:identity\n",
      "[TL] ConcatLayer unet/encoder/convblock_2/concat: axis: -1\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_2/in: epsilon:0.000010 act:identity\n",
      "[TL] ElementwiseLayer unet/encoder/convblock_2/merge_last: size:(1, 64, 64, 512) fn:add\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_2/nrom_last: epsilon:0.000010 act:identity\n",
      "[TL] PoolLayer   unet/encoder/maxplool3: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/convblock_3/conv2d_conv2d: shape:(1, 1, 512, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_3/conv2din: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_3/conv_block1_conv2d: shape:(3, 3, 512, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_3/conv_block1in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_3/conv_block2_conv2d: shape:(3, 3, 128, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_3/conv_block2in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_3/conv_block3_conv2d: shape:(3, 3, 128, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_3/conv_block3in: epsilon:0.000010 act:identity\n",
      "[TL] ConcatLayer unet/encoder/convblock_3/concat: axis: -1\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_3/in: epsilon:0.000010 act:identity\n",
      "[TL] ElementwiseLayer unet/encoder/convblock_3/merge_last: size:(1, 32, 32, 512) fn:add\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_3/nrom_last: epsilon:0.000010 act:identity\n",
      "[TL] PoolLayer   unet/encoder/maxplool4: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer unet/encoder/convblock_4/conv2d_conv2d: shape:(1, 1, 512, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_4/conv2din: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_4/conv_block1_conv2d: shape:(3, 3, 512, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_4/conv_block1in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_4/conv_block2_conv2d: shape:(3, 3, 128, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_4/conv_block2in: epsilon:0.000010 act:identity\n",
      "[TL] Conv2dLayer unet/encoder/convblock_4/conv_block3_conv2d: shape:(3, 3, 128, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_4/conv_block3in: epsilon:0.000010 act:identity\n",
      "[TL] ConcatLayer unet/encoder/convblock_4/concat: axis: -1\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_4/in: epsilon:0.000010 act:identity\n",
      "[TL] ElementwiseLayer unet/encoder/convblock_4/merge_last: size:(1, 16, 16, 512) fn:add\n",
      "[TL] InstanceNormLayer unet/encoder/convblock_4/nrom_last: epsilon:0.000010 act:identity\n",
      "[TL] PoolLayer   unet/encoder/maxplool5: ksize:[1, 3, 3, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] UpSampling2dLayer upsamplimg: is_scale:False size:(16, 16) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat1: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv2: shape:(3, 3, 1024, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/decoder/in2: epsilon:0.000010 act:identity\n",
      "[TL] UpSampling2dLayer upsamplimg2: is_scale:False size:(32, 32) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat2: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv3: shape:(3, 3, 1024, 512) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/decoder/in3: epsilon:0.000010 act:identity\n",
      "[TL] UpSampling2dLayer upsamplimg3: is_scale:False size:(64, 64) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat3: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv4: shape:(3, 3, 768, 256) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/decoder/in4: epsilon:0.000010 act:identity\n",
      "[TL] UpSampling2dLayer upsamplimg4: is_scale:False size:(128, 128) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat4: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv5: shape:(3, 3, 384, 128) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/decoder/in5: epsilon:0.000010 act:identity\n",
      "[TL] UpSampling2dLayer upsamplimg5: is_scale:False size:(256, 256) method:0 align_corners:False\n",
      "[TL] ConcatLayer unet/decoder/concat5: axis: -1\n",
      "[TL] Conv2dLayer unet/decoder/conv6: shape:(3, 3, 192, 61) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] InstanceNormLayer unet/decoder/in6: epsilon:0.000010 act:identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] UpSampling2dLayer upsamplimg6: is_scale:False size:(256, 256) method:0 align_corners:False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder 4 : (1, 16, 16, 512)\n",
      "decoder 3 : (1, 32, 32, 512)\n",
      "decoder 2 : (1, 64, 64, 512)\n",
      "decoder 1 : (1, 128, 128, 256)\n",
      "decoder 0 : (1, 256, 256, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] UpSampling2dLayer resize_final: is_scale:False size:[240, 240] method:0 align_corners:False\n",
      "[TL] Conv2dLayer unet/decoder/conv_final: shape:(3, 3, 61, 61) strides:(1, 1, 1, 1) pad:SAME act:identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\eval.py:99: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\eval.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\layers\\core.py:315: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "loading E:\\Dropbox\\Python\\VCD-Net\\vcd-example-data\\checkpoint\\tubulin_10x06_N15_OSR3_Crop240\\/vcdnet_best.npz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8390374e2938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0muse_cpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Dropbox\\Python\\VCD-Net\\vcdnet\\eval.py\u001b[0m in \u001b[0;36minfer\u001b[1;34m(epoch, batch_size, use_cpu, save_pb)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mckpt_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mckpt_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loading %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mckpt_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_and_assign_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mckpt_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msave_pb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\files.py\u001b[0m in \u001b[0;36mload_and_assign_npz\u001b[1;34m(sess, name, network)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1359\u001b[0m         \u001b[0massign_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[*] Load {} SUCCESS!\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\Python\\VCD-Net\\vcdnet\\tensorlayer\\files.py\u001b[0m in \u001b[0;36mload_npz\u001b[1;34m(path, name, encoding)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \"\"\"\n\u001b[0;32m   1290\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vcdnet\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[0;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vcdnet\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[0;32m    740\u001b[0m                              \"allow_pickle=False\")\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "ckpt = 0 #0 means latest\n",
    "batch_size = 1\n",
    "use_cpu = 1                                             \n",
    "infer(ckpt, batch_size=batch_size, use_cpu=use_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "\n",
    "test_file = 'vcd-001-000009.tif'\n",
    "recon = get_and_rearrange3d(test_file, config.VALID.saving_path, normalize)\n",
    "# recons=np.ndarray([recon.shape[0],recon.shape[1],recon.shape[2],3])\n",
    "\n",
    "f=ipv.quickvolshow(recon)\n",
    "ipv.show()\n",
    "\n",
    "# ##threshold\n",
    "# a,b,c=np.where(recon>=0.1)\n",
    "# a=np.asarray(a,dtype='float64')\n",
    "# b=np.asarray(b,dtype='float64')\n",
    "# c=np.asarray(c,dtype='float64')\n",
    "\n",
    "# ##scatter\n",
    "# # f=ipv.quickscatter(a,b,c)\n",
    "# ipv.show()\n",
    "\n",
    "# ##surface\n",
    "# from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "# points=np.concatenate((np.expand_dims(a,axis=1),np.expand_dims(b,axis=1),np.expand_dims(c,axis=1)),axis=1)\n",
    "# hull = ConvexHull(points)\n",
    "# f=ipv.plot_trisurf(a,b,c, triangles=hull.simplices, color='red') ##surface\n",
    "# ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##bokeh embeds ipv figures as html exceeds the char limit for squarespace \n",
    "import ipyvolume\n",
    "import ipyvolume as ipv\n",
    "import vaex\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import CustomJS, ColumnDataSource\n",
    "import ipyvolume.bokeh\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.embed import components\n",
    "import ipywidgets\n",
    "\n",
    "ds = vaex.example()\n",
    "N = 5\n",
    "\n",
    "ipv.figure()\n",
    "quiver = ipv.quiver(ds.data.x[:N],  ds.data.y[:N],  ds.data.z[:N],\n",
    "                    ds.data.vx[:N], ds.data.vy[:N], ds.data.vz[:N],\n",
    "                    size=1, size_selected=5, color_selected=\"grey\")\n",
    "ipv.xyzlim(-30, 30)\n",
    "ipv.show()\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "xin=ds.data.Lz[:N]\n",
    "yin=ds.data.E[:N]\n",
    "data_source = ColumnDataSource(data=dict(x=xin.astype('uint8'), y=yin.astype('uint8')))\n",
    "p = figure(title=\"E Lz space\", tools='lasso_select', width=500, height=500)\n",
    "r = p.circle('x', 'y', source=data_source, color=\"navy\", alpha=0.2)\n",
    "ipyvolume.bokeh.link_data_source_selection_to_widget(data_source, quiver, 'selected')\n",
    "show(p)\n",
    "\n",
    "out = ipywidgets.Output()\n",
    "with out:\n",
    "    show(p)\n",
    "ipywidgets.HBox([out, ipv.gcc()])\n",
    "\n",
    "script, div = components((p))\n",
    "template_options = dict(extra_script_head=script + CDN.render_js() + CDN.render_css(),\n",
    "                        body_pre=\"<h2>Do selections in 2d (bokeh)<h2>\" + div + \"<h2>And see the selection in ipyvolume<h2>\")\n",
    "figCode=ipyvolume.embed.embed_html(\"tmp/bokeh.html\",\n",
    "                           [ipv.gcc(), ipyvolume.bokeh.wmh], all_states=True,\n",
    "                           template_options=template_options)\n",
    "\n",
    "!open tmp/bokeh.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=ipv.scatter(np.random.randn(1,10),np.random.randn(1,10),np.random.randn(1,10))\n",
    "f.send_state('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import mpld3\n",
    "\n",
    "test_file = 'vcd-001-000000.tif'\n",
    "recon = get_and_rearrange3d(test_file, config.VALID.saving_path, normalize)\n",
    "print(recon.shape)\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[recon.shape[0],recon.shape[2]*1/0.34]) \n",
    "xy_view = plt.subplot(gs[0])\n",
    "xy_view.imshow(np.sum(recon, axis=-1, keepdims=False),cmap='hot')\n",
    "xy_view.set_title('VCD-XY')\n",
    "plt.axis('off')\n",
    "xz_view = plt.subplot(gs[1])\n",
    "xz_view.imshow(np.transpose(np.sum(recon, axis=0, keepdims=False)),cmap='hot',aspect=1/0.34)\n",
    "xz_view.set_title('VCD-XZ')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "##create html file\n",
    "html_str = mpld3.fig_to_html(fig)\n",
    "Html_file= open(\"index.html\",\"w\")\n",
    "Html_file.write(html_str)\n",
    "Html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vcdnet",
   "language": "python",
   "name": "vcdnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
